[2025-02-10T19:53:34.285+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-10T19:53:34.298+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: web_to_snowflake.create_s3_stage manual__2025-02-10T19:48:25.747806+00:00 [queued]>
[2025-02-10T19:53:34.304+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: web_to_snowflake.create_s3_stage manual__2025-02-10T19:48:25.747806+00:00 [queued]>
[2025-02-10T19:53:34.305+0000] {taskinstance.py:2866} INFO - Starting attempt 2 of 2
[2025-02-10T19:53:34.313+0000] {taskinstance.py:2889} INFO - Executing <Task(SnowflakeOperator): create_s3_stage> on 2025-02-10 19:48:25.747806+00:00
[2025-02-10T19:53:34.320+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=5330) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-02-10T19:53:34.322+0000] {standard_task_runner.py:72} INFO - Started process 5332 to run task
[2025-02-10T19:53:34.322+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'web_to_snowflake', 'create_s3_stage', 'manual__2025-02-10T19:48:25.747806+00:00', '--job-id', '39', '--raw', '--subdir', 'DAGS_FOLDER/web_to_snowflake.py', '--cfg-path', '/tmp/tmp80a5rw4t']
[2025-02-10T19:53:34.324+0000] {standard_task_runner.py:105} INFO - Job 39: Subtask create_s3_stage
[2025-02-10T19:53:34.360+0000] {task_command.py:467} INFO - Running <TaskInstance: web_to_snowflake.create_s3_stage manual__2025-02-10T19:48:25.747806+00:00 [running]> on host 0370ed89eba8
[2025-02-10T19:53:34.427+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='your-email@example.com' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='web_to_snowflake' AIRFLOW_CTX_TASK_ID='create_s3_stage' AIRFLOW_CTX_EXECUTION_DATE='2025-02-10T19:48:25.747806+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-10T19:48:25.747806+00:00'
[2025-02-10T19:53:34.428+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-02-10T19:53:34.438+0000] {sql.py:278} INFO - Executing: 
    CREATE STAGE IF NOT EXISTS my_s3_stage
    URL='s3://cfapublications/weather/raw/'
    CREDENTIALS=(AWS_KEY_ID='AKIA47CRWJS4AWXARWZI'
                AWS_SECRET_KEY='***');
    
[2025-02-10T19:53:34.445+0000] {base.py:84} INFO - Retrieving connection 'snowflake_default'
[2025-02-10T19:53:34.452+0000] {base.py:84} INFO - Retrieving connection 'snowflake_default'
[2025-02-10T19:53:34.453+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.12.8, Platform: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-02-10T19:53:34.454+0000] {connection.py:1197} INFO - Connecting to GLOBAL Snowflake domain
[2025-02-10T19:53:34.454+0000] {connection.py:1278} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-02-10T19:53:34.455+0000] {connection.py:1288} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2025-02-10T19:53:34.847+0000] {ssl_wrap_socket.py:101} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2025-02-10T19:53:35.350+0000] {cursor.py:1166} INFO - Number of results in first chunk: 1
[2025-02-10T19:53:35.351+0000] {sql.py:553} INFO - Running statement: CREATE STAGE IF NOT EXISTS my_s3_stage
    URL='s3://cfapublications/weather/raw/'
    CREDENTIALS=(AWS_KEY_ID='AKIA47CRWJS4AWXARWZI'
                AWS_SECRET_KEY='***');, parameters: None
[2025-02-10T19:53:35.443+0000] {connection.py:789} INFO - closed
[2025-02-10T19:53:35.497+0000] {connection.py:795} INFO - No async queries seem to be running, deleting session
[2025-02-10T19:53:35.565+0000] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 284, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 435, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 558, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1097, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 090106 (22000): 01ba4dd2-3202-c1b2-0005-f712000210c6: Cannot perform CREATE STAGE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.
[2025-02-10T19:53:35.573+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=web_to_snowflake, task_id=create_s3_stage, run_id=manual__2025-02-10T19:48:25.747806+00:00, execution_date=20250210T194825, start_date=20250210T195334, end_date=20250210T195335
[2025-02-10T19:53:35.583+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-02-10T19:53:35.585+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 39 for task create_s3_stage (090106 (22000): 01ba4dd2-3202-c1b2-0005-f712000210c6: Cannot perform CREATE STAGE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.; 5332)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 284, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 435, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 558, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1097, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 090106 (22000): 01ba4dd2-3202-c1b2-0005-f712000210c6: Cannot perform CREATE STAGE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.
[2025-02-10T19:53:35.620+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-10T19:53:35.641+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-10T19:53:35.645+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
